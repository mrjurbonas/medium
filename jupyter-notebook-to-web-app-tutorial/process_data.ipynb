{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook you will load data sets, combine then all, remove features which will not be used,<br>\n",
        "scale data and save it as a pickle file to use to produce plots."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "import os\n",
        "\n",
        "%load_ext lab_black"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv(csv_path):\n",
        "    \"\"\"\n",
        "    This function read csv from default Blob Storage which\n",
        "    is attached to Machine Learning resource\n",
        "    using Azure ML SDK and returns data as pandas dataframe.    \n",
        "    \"\"\"\n",
        "\n",
        "    # log in the Machine Learning resource\n",
        "    ws = Workspace.from_config()\n",
        "\n",
        "    # connect to the data store\n",
        "    datastore_name = \"workspaceblobstore\"  # using default blob\n",
        "    datastore = Datastore.get(ws, datastore_name=datastore_name)\n",
        "\n",
        "    # get a file from the datastore\n",
        "    data_paths = [(datastore, csv_path)]\n",
        "    ds = Dataset.Tabular.from_delimited_files(data_paths)\n",
        "\n",
        "    # convert the dataframe to a pandas dataframe\n",
        "    df = ds.to_pandas_dataframe()\n",
        "\n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Read datasets into memory\n",
        "measurements = read_csv(\"Measurement_info.csv\")\n",
        "item_info = read_csv(\"Measurement_item_info.csv\")\n",
        "station_info = read_csv(\"Measurement_station_info.csv\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all data into one dataset\n",
        "data = measurements.merge(item_info, on=\"Item code\").merge(\n",
        "    station_info, on=\"Station code\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing unecessary columns\n",
        "data = data[\n",
        "    [\n",
        "        \"Measurement date\",\n",
        "        \"Average value\",\n",
        "        \"Item name\",\n",
        "        \"Unit of measurement\",\n",
        "        \"Station name(district)\",\n",
        "    ]\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract date from \"Measurement date\"\n",
        "data[\"DayDate\"] = data[\"Measurement date\"].apply(lambda x: x[:10])\n",
        "\n",
        "# Aggregate data to average per day instead of average per hour\n",
        "data_avg = data.groupby([\"Station name(district)\", \"Item name\", \"DayDate\"]).agg(\"mean\")\n",
        "\n",
        "# Remove multi index structure from aggregated dataset\n",
        "data = pd.melt(data_avg.T)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Change \"DayDate\" to datetime format\n",
        "data[\"DayDate\"] = pd.to_datetime(data[\"DayDate\"], format=\"%Y-%m-%d\")\n",
        "# Get string representation of date which will be used for x axis labels\n",
        "data[\"Date\"] = data[\"DayDate\"].apply(lambda x: x.strftime(\"%y-%m-%d\"))\n",
        "# Get day name\n",
        "data[\"DayName\"] = data[\"DayDate\"].apply(lambda x: x.day_name())"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save it"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Save it locally\n",
        "os.mkdir(\"data\")\n",
        "data.to_pickle(\"data/data_for_plots.pkl\")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload it to default blob storage\n",
        "\n",
        "# log in the Machine Learning resource\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Connect to the data store\n",
        "datastore_name = \"workspaceblobstore\"\n",
        "datastore = Datastore.get(ws, datastore_name=datastore_name)\n",
        "\n",
        "# upload pickle file\n",
        "pickle_file_directory = os.getcwd() + \"/data/\"\n",
        "datastore.upload(\n",
        "    src_dir=pickle_file_directory, target_path=\"/\", overwrite=True, show_progress=True\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 1 files\n",
            "Uploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/my-example-compute/code/data/data_for_plots.pkl\n",
            "Uploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/my-example-compute/code/data/data_for_plots.pkl, 1 files out of an estimated total of 1\n",
            "Uploaded 1 files\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": [
              "$AZUREML_DATAREFERENCE_workspaceblobstore"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nteract": {
      "version": "0.23.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}