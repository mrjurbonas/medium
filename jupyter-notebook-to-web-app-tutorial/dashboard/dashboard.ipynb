{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML, clear_output, display\n",
    "from ipywidgets import HBox, VBox\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processed by process_data.ipynb notebook is stored locally\n",
    "# in your Machine Learning environment. Also, the processed data\n",
    "# is uploaded to the default blob storage. Mount default blob storage\n",
    "# to your Azure Web App as \"/ml_blob_storage\" folder. This way the processed\n",
    "# dataset will be available in \"/ml_blob_storage\" folder for your web app.\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    # You need to use \"/ml_blob_storage\" as a mount path to mount Azure Storage\n",
    "    # in Azure Web App configuration\n",
    "    data = pd.read_pickle(\n",
    "        \"/ml_blob_storage/data_for_plots.pkl\"\n",
    "    )  # This path is used to load data for web app\n",
    "except FileNotFoundError:\n",
    "    # local (on Azure Machine Learning) data file structure:\n",
    "    # process_data.ipynb\n",
    "    # |-- data /\n",
    "    # |   |-- data_for_plots.pkl\n",
    "    # |-- dashbaord /\n",
    "    # |   |-- dashboard.ipynb\n",
    "    # |   |-- Dockerfile\n",
    "    # |   |-- requirements.txt\n",
    "    data = pd.read_pickle(\n",
    "        \"../data/data_for_plots.pkl\"\n",
    "    )  # This path is used to load data while working in AMLS environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_values_per_item(data):\n",
    "    \"\"\"\n",
    "    This function removes outliers and calculates scaled values\n",
    "    for each type of measurement CO, SO2, etc.\n",
    "    Scaled values will be used to adjust the colour of the cells in a heat map.\n",
    "    This way the colour scale will not go out of range for chosen dates. The actual,\n",
    "    recorded values will be displayed via tool tip on the heat map.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for name, values in data.groupby(\"Item name\"):\n",
    "        copy_of_data = values.copy(deep=True)\n",
    "        # array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1)\n",
    "        actaul_values = np.array(copy_of_data[\"value\"]).reshape(-1, 1)\n",
    "\n",
    "        # This will copy the array of values then\n",
    "        # scale the values by removing mean and dividing by standard deviation (std)\n",
    "        # if std is greated than X the observations with those values will be removed and\n",
    "        # the process will be repeated until all the outliers are removed\n",
    "        copy_of_values = actaul_values.copy()\n",
    "        max_std = 5\n",
    "        std_above = True\n",
    "        while std_above:\n",
    "            # scale the values\n",
    "            scaler = StandardScaler()\n",
    "            scalled_values = scaler.fit_transform(copy_of_values)\n",
    "            # check for outliers\n",
    "            if max(scalled_values) > max_std:\n",
    "                mask = scalled_values > max_std\n",
    "                copy_of_values[mask] = -99\n",
    "            else:\n",
    "                std_above = False\n",
    "\n",
    "        # add scalled value to the main dataframe\n",
    "        copy_of_data[\"value_scalled\"] = scalled_values.reshape(-1)\n",
    "\n",
    "        all_data.append(copy_of_data)\n",
    "\n",
    "    all_data = pd.concat(all_data).reset_index(drop=True)\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_date(data, start_date, end_date):\n",
    "    \"\"\"\n",
    "    e.g.\n",
    "    start_date = \"2017-01-01\"\n",
    "    end_date = \"2017-03-01\"\n",
    "    \"\"\"\n",
    "    mask = (data[\"DayDate\"] > start_date) & (data[\"DayDate\"] <= end_date)\n",
    "    filterd_data = data[mask]\n",
    "\n",
    "    return filterd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air Pollution Measurement Information in Seoul, Korea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data available from 2017-01-01 00:00:00 to 2019-12-31 00:00:00 dates.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data available from {data['DayDate'].min()} to {data['DayDate'].max()} dates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create start, end date and station picker and their labels\n",
    "# to allow dynamic interaction with the plot\n",
    "all_station_names = data[\"Station name(district)\"].unique()\n",
    "\n",
    "station_name_label = widgets.Label(value=\"Station name:\")\n",
    "station_name_picker = widgets.Dropdown(\n",
    "    options=all_station_names, value=all_station_names[0],\n",
    ")\n",
    "\n",
    "start_date_label = widgets.Label(value=\"Start date:\")\n",
    "start_date_picker = widgets.DatePicker()\n",
    "\n",
    "end_date_label = widgets.Label(value=\"End date:\")\n",
    "end_date_picker = widgets.DatePicker()\n",
    "\n",
    "left = widgets.VBox([start_date_label, end_date_label, station_name_label])\n",
    "right = widgets.VBox([start_date_picker, end_date_picker, station_name_picker])\n",
    "\n",
    "legend = widgets.Label(\n",
    "    value=\"Colour represents recorded values for each measurement from low - blue to high - red.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d361ce16bd4e55bab4951b8e3f4429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = widgets.VBox([widgets.HBox([left, right]), legend])  # Labels\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "def plot(change):\n",
    "    start_date = start_date_picker.value\n",
    "    end_date = end_date_picker.value\n",
    "    station_name = station_name_picker.value\n",
    "    error_message = \"\"\n",
    "\n",
    "    with out:\n",
    "        # Set some default dates before you use date picker\n",
    "        if start_date == None:\n",
    "            start_date = datetime.strptime(\"2017-01-01\", \"%Y-%m-%d\")\n",
    "            end_date = datetime.strptime(\"2017-03-01\", \"%Y-%m-%d\")\n",
    "\n",
    "        min_date = data[\"DayDate\"].min()\n",
    "        max_date = data[\"DayDate\"].max()\n",
    "\n",
    "        plot = None\n",
    "\n",
    "        try:\n",
    "            # Error handling, checking if dates are within the range.\n",
    "            if start_date:\n",
    "                start_date = pd.to_datetime(start_date)\n",
    "                if start_date < min_date:\n",
    "                    raise Exception(f\"Date out of range. Min date available {min_date}\")\n",
    "            if end_date:\n",
    "                end_date = pd.to_datetime(end_date)\n",
    "                if end_date > max_date:\n",
    "                    raise Exception(f\"Date out of range. Max date available {max_date}\")\n",
    "            if (start_date != None) & (end_date != None):\n",
    "                difference = (end_date - start_date).days\n",
    "                if difference > 60:\n",
    "                    raise Exception(\n",
    "                        f\"Currently only 60 day range can be displayed. Your date range is {difference} days\"\n",
    "                    )\n",
    "\n",
    "            station_data = data[data[\"Station name(district)\"] == station_name]\n",
    "            station_data = filter_by_date(station_data, start_date, end_date)\n",
    "            station_data = scale_values_per_item(station_data)\n",
    "\n",
    "            plot = (\n",
    "                alt.Chart(station_data)\n",
    "                .mark_rect()\n",
    "                .encode(\n",
    "                    x=alt.X(\"Date\", sort=\"ascending\"),\n",
    "                    y=alt.Y(\"Item name:O\", title=\"\"),\n",
    "                    color=alt.Color(\n",
    "                        \"value_scalled:Q\",\n",
    "                        scale=alt.Scale(scheme=\"redyellowblue\", domain=[-4, 4]),\n",
    "                        sort=\"descending\",\n",
    "                        legend=None,\n",
    "                    ),\n",
    "                    tooltip=[\n",
    "                        alt.Tooltip(\"Date:O\", title=\"Date\"),\n",
    "                        alt.Tooltip(\"DayName:O\", title=\"Week day\"),\n",
    "                        alt.Tooltip(\"Item name:O\", title=\"Measurement\"),\n",
    "                        alt.Tooltip(\"value:Q\", title=\"Value\", format=\",.3f\"),\n",
    "                    ],\n",
    "                )\n",
    "            ).properties(height=100, width=840)\n",
    "        except TypeError:\n",
    "            error_message = \"Please choose both start and end dates.\"\n",
    "        except Exception as error:\n",
    "            error_message = error\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(labels, plot, error_message)\n",
    "\n",
    "\n",
    "start_date_picker.observe(plot, names=\"value\")\n",
    "end_date_picker.observe(plot, names=\"value\")\n",
    "station_name_picker.observe(plot, names=\"value\")\n",
    "\n",
    "plot(None)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe width=\"640px\" height= \"1080px\"\n",
       "    src= \"https://forms.office.com/Pages/ResponsePage.aspx?id=Ah2656Iq1UiBhePca_e4bXaJLBhM1sJFnZ5dBLvC2X9UQVNSSlBTN1I2MVNHUkJUREgwR0FDWVZUNy4u&embed=true\"\n",
       "    frameborder= \"0\"\n",
       "    marginwidth= \"0\"\n",
       "    marginheight= \"0\"\n",
       "    style= \"border: none;\n",
       "    max-width:100%\" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\n",
    "    \"\"\"\n",
    "    <iframe width=\"640px\" height= \"1080px\"\n",
    "    src= \"https://forms.office.com/Pages/ResponsePage.aspx?id=Ah2656Iq1UiBhePca_e4bXaJLBhM1sJFnZ5dBLvC2X9UQVNSSlBTN1I2MVNHUkJUREgwR0FDWVZUNy4u&embed=true\"\n",
    "    frameborder= \"0\"\n",
    "    marginwidth= \"0\"\n",
    "    marginheight= \"0\"\n",
    "    style= \"border: none;\n",
    "    max-width:100%\" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe>\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}